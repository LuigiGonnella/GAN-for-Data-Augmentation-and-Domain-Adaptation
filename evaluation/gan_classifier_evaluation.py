"""
Classifier-based evaluation for GAN-generated samples.
Provides tools to evaluate synthetic medical images using a pre-trained classifier.
"""

import torch
import torch.nn as nn
from torchvision import transforms
from torch.utils.data import DataLoader, Dataset
from PIL import Image
from pathlib import Path
import sys
import yaml

sys.path.insert(0, str(Path(__file__).parent.parent))

from models.classifier.classifier import Classifier
from models.gan.DCGAN import DCGANGenerator
from models.gan.cDCGAN import ConditionalDCGANGenerator
from evaluation.classifier_metrics import evaluate
from evaluation.plots import plot_cm
import matplotlib.pyplot as plt


# Classifier configuration
CLASSIFIER_PATH = 'results/classifier_on_baseline/ft_ht/classifier.pth'
DEFAULT_CLASSIFIER_CONFIG = {
    'model': {'name': 'resnet50'},
    'training': {'params': {'batch_size': 32}}
}

# Default evaluation parameters
DEFAULT_NUM_SAMPLES = 500
DEFAULT_BATCH_SIZE = 64


class SyntheticDataset(Dataset):
    """Dataset for synthetic images generated by GAN"""
    def __init__(self, images, labels=None, transform=None):
        """
        Args:
            images: List of PIL Images
            labels: List of labels (if None, all set to 1 for malignant)
            transform: Optional transform to be applied on images
        """
        self.images = images
        self.transform = transform
        # All synthetic images are malignant (label=1) by default
        self.labels = labels if labels is not None else [1] * len(images)
    
    def __len__(self):
        return len(self.images)
    
    def __getitem__(self, idx):
        image = self.images[idx]
        if self.transform:
            image = self.transform(image)
        return image, self.labels[idx]


def generate_samples_for_evaluation(generator_path, config, num_samples=DEFAULT_NUM_SAMPLES, 
                                    batch_size=DEFAULT_BATCH_SIZE, device='cuda', 
                                    gan_type='dcgan', num_classes=None):
    """
    Generate synthetic samples from a trained generator for classifier evaluation
    
    Args:
        generator_path: Path to generator checkpoint
        config: GAN config dict
        num_samples: Number of samples to generate
        batch_size: Batch size for generation
        device: Device to use ('cuda' or 'cpu')
        gan_type: Type of GAN ('dcgan' or 'cdcgan')
        num_classes: Number of classes for conditional GAN (required if gan_type='cdcgan')
        
    Returns:
        List of PIL Images
    """
    device = torch.device(device if torch.cuda.is_available() else 'cpu')
    gen_config = config['model']['generator']
    
    # Initialize appropriate generator based on type
    if gan_type.lower() == 'cdcgan':
        if num_classes is None:
            raise ValueError("num_classes must be specified for conditional GAN")
        generator = ConditionalDCGANGenerator(
            input_dim=gen_config['latent_dim'],
            num_classes=num_classes,
            n1=gen_config['n1'],
            channels=gen_config['channels']
        ).to(device)
    else:  # dcgan
        generator = DCGANGenerator(
            input_dim=gen_config['latent_dim'],
            n1=gen_config['n1'],
            channels=gen_config['channels']
        ).to(device)
    
    # Load checkpoint
    checkpoint = torch.load(generator_path, map_location=device, weights_only=False)
    if isinstance(checkpoint, dict) and 'generator' in checkpoint:
        generator.load_state_dict(checkpoint['generator'])
    else:
        generator.load_state_dict(checkpoint)
    
    generator.eval()
    latent_dim = gen_config['latent_dim']
    
    images = []
    num_batches = (num_samples + batch_size - 1) // batch_size
    
    with torch.no_grad():
        for _ in range(num_batches):
            current_batch_size = min(batch_size, num_samples - len(images))
            z = torch.randn(current_batch_size, latent_dim, device=device)
            
            # Generate based on GAN type
            if gan_type.lower() == 'cdcgan':
                # For conditional GAN, generate malignant class (label=1)
                labels = torch.ones(current_batch_size, dtype=torch.long, device=device)
                batch_images = generator(z, labels)
            else:
                batch_images = generator(z)
            
            # Convert from [-1, 1] to [0, 1]
            batch_images = (batch_images + 1) / 2
            batch_images = torch.clamp(batch_images, 0, 1)
            
            # Convert to PIL Images
            for i in range(current_batch_size):
                img_tensor = batch_images[i].cpu()
                # Convert from [C, H, W] to [H, W, C] and scale to [0, 255]
                img_np = (img_tensor.permute(1, 2, 0).numpy() * 255).astype('uint8')
                pil_img = Image.fromarray(img_np)
                images.append(pil_img)
    
    return images


def evaluate_and_plot_classifier(generator_path, gan_config, plot_dir, iter_id,
                                 num_samples=DEFAULT_NUM_SAMPLES,
                                 classifier_path=None, classifier_config=None,
                                 gan_type='dcgan', num_classes=None):
    """
    Evaluate generated samples with classifier and create plots
    
    Args:
        generator_path: Path to generator checkpoint
        gan_config: GAN configuration dict
        plot_dir: Directory to save plots
        iter_id: Iteration identifier for plot naming
        num_samples: Number of samples to generate and evaluate
        classifier_path: Path to classifier checkpoint (uses default if None)
        classifier_config: Classifier config dict or path to yaml file
        gan_type: Type of GAN ('dcgan' or 'cdcgan')
        num_classes: Number of classes for conditional GAN
        
    Returns:
        Dict with precision, recall, accuracy, f1, confusion_matrix
    """
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # Use provided classifier path or default
    clf_path = classifier_path if classifier_path is not None else CLASSIFIER_PATH
    
    # Load classifier config
    if classifier_config is None:
        clf_config = DEFAULT_CLASSIFIER_CONFIG
    elif isinstance(classifier_config, str):
        with open(classifier_config, 'r') as f:
            clf_config = yaml.safe_load(f)
    else:
        clf_config = classifier_config
    
    # Load classifier
    classifier = Classifier(
        num_classes=2,
        model_name=clf_config['model']['name'],
        pretrained=False
    ).to(device)
    classifier.load_state_dict(torch.load(clf_path, map_location=device, weights_only=False))
    classifier.eval()
    
    # Generate synthetic samples
    print(f"  Generating {num_samples} samples for classifier evaluation...")
    synthetic_images = generate_samples_for_evaluation(
        generator_path, gan_config, num_samples, device=device,
        gan_type=gan_type, num_classes=num_classes
    )
    
    # Create dataset and dataloader
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])
    
    dataset = SyntheticDataset(synthetic_images, transform=transform)
    dataloader = DataLoader(dataset, batch_size=32, shuffle=False, num_workers=0)
    
    # Evaluate
    criterion = nn.CrossEntropyLoss()
    _, accuracy, f1, recall, precision, roc_auc, cm, _, _ = evaluate(
        classifier, dataloader, criterion, device, optimal_threshold=0.5
    )
    
    # Create plots directory
    Path(plot_dir).mkdir(parents=True, exist_ok=True)
    
    # Plot confusion matrix
    cm_path = Path(plot_dir) / f'confusion_matrix_iter_{iter_id}.png'
    plt.figure(figsize=(8, 6))
    import seaborn as sns
    sns.heatmap(cm, annot=True, cbar=False, cmap='GnBu', annot_kws={'size':16}, fmt='g',
                xticklabels=['Benign', 'Malignant'], yticklabels=['Benign', 'Malignant'])
    plt.xlabel('Predicted', fontsize=12)
    plt.ylabel('Actual', fontsize=12)
    plt.title(f'Confusion Matrix - Iteration {iter_id}', fontsize=14)
    plt.tight_layout()
    plt.savefig(cm_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"  Saved confusion matrix to: {cm_path}")
    
    # Plot metrics bar chart
    metrics_path = Path(plot_dir) / f'metrics_iter_{iter_id}.png'
    metrics = {
        'Precision': precision,
        'Recall': recall,
        'F1-Score': f1,
        'Accuracy': accuracy
    }
    
    plt.figure(figsize=(10, 6))
    bars = plt.bar(metrics.keys(), metrics.values(), color=['#3498db', '#e74c3c', '#2ecc71', '#f39c12'])
    plt.ylim(0, 1.0)
    plt.ylabel('Score', fontsize=12)
    plt.title(f'Classification Metrics - Iteration {iter_id}', fontsize=14)
    plt.grid(axis='y', alpha=0.3)
    
    # Add value labels on bars
    for bar in bars:
        height = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2., height,
                f'{height:.3f}',
                ha='center', va='bottom', fontsize=11, fontweight='bold')
    
    plt.tight_layout()
    plt.savefig(metrics_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"  Saved metrics plot to: {metrics_path}")
    
    return {
        'precision': precision,
        'recall': recall,
        'accuracy': accuracy,
        'f1': f1,
        'confusion_matrix': cm
    }


def compute_combined_score(fid_score, recall, fid_scores_list=None, 
                          recall_weight=0.6, fid_weight=0.4):
    """
    Compute combined score from FID and recall metrics
    
    Args:
        fid_score: FID score for this model
        recall: Recall score from classifier evaluation
        fid_scores_list: List of all FID scores for normalization (optional)
        recall_weight: Weight for recall component (default 0.6)
        fid_weight: Weight for FID component (default 0.4)
        
    Returns:
        Combined score (lower is better)
    """
    # Normalize FID if list provided
    if fid_scores_list is not None and len(fid_scores_list) > 1:
        max_fid = max(fid_scores_list)
        min_fid = min(fid_scores_list)
        fid_range = max_fid - min_fid if max_fid > min_fid else 1.0
        norm_fid = (fid_score - min_fid) / fid_range
    else:
        norm_fid = fid_score / 1000.0  # Simple normalization
    
    # Negative recall because we want to maximize it (lower score = better)
    combined_score = -recall_weight * recall + fid_weight * norm_fid
    
    return combined_score
